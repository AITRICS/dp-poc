# dp-poc

ì´ë²¤íŠ¸ ê¸°ë°˜ ë°ì´í„° í”Œë«í¼ì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¥¼ êµ¬í˜„í•œ PoC(Proof of Concept) í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.


## ğŸ“Š Taskì˜ ì „ì²´ ìƒëª…ì£¼ê¸° (Life Cycle)

### 1ë‹¨ê³„: Task ì •ì˜ ë° ë“±ë¡ ğŸ“

```
ê°œë°œìê°€ ì½”ë“œ ì‘ì„±
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@task(name="extract_sales", tags=["etl"])
def extract_sales() -> pd.DataFrame:
    return pd.DataFrame({"sales": [100, 200]})

@task(name="transform", dependencies=["extract_sales"])
def transform(extract_sales: pd.DataFrame) -> pd.DataFrame:
    return extract_sales * 2

         â†“ decoratorê°€ ìë™ìœ¼ë¡œ ì²˜ë¦¬

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      TaskRegistry (ì „ì—­ ì €ì¥ì†Œ)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  "extract_sales" â†’ TaskMetadata {      â”‚
â”‚    name: "extract_sales"               â”‚
â”‚    func: <function extract_sales>      â”‚
â”‚    dependencies: []                    â”‚
â”‚    tags: ["etl"]                       â”‚
â”‚  }                                     â”‚
â”‚                                        â”‚
â”‚  "transform" â†’ TaskMetadata {          â”‚
â”‚    name: "transform"                   â”‚
â”‚    func: <function transform>          â”‚
â”‚    dependencies: ["extract_sales"]     â”‚
â”‚  }                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2ë‹¨ê³„: DAG ë¹Œë“œ ğŸ—ï¸

```
ì‚¬ìš©ìê°€ ì‹¤í–‰ ìš”ì²­
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
planner = Planner(DAGBuilder(registry))
execution_plan = planner.create_execution_plan(
    tags=["etl"]
)

         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          DAGBuilder                     â”‚
â”‚  TaskRegistryì—ì„œ Taskë“¤ ê°€ì ¸ì˜´         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DAG                        â”‚
â”‚  (TaskMetadataë“¤ì˜ ê´€ê³„ ê·¸ë˜í”„)         â”‚
â”‚                                         â”‚
â”‚     extract_sales (Node)                â”‚
â”‚         â†“                               â”‚
â”‚     transform (Node)                    â”‚
â”‚                                         â”‚
â”‚  ê° Nodeê°€ TaskMetadataë¥¼ ì°¸ì¡°          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“ DAGAnalyzer ì‹¤í–‰

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ExecutionPlan                   â”‚
â”‚  (ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„íš)                     â”‚
â”‚                                         â”‚
â”‚  execution_order: ["extract_sales",    â”‚
â”‚                    "transform"]         â”‚
â”‚  parallel_levels: [                    â”‚
â”‚    ["extract_sales"],  # Level 0       â”‚
â”‚    ["transform"]       # Level 1       â”‚
â”‚  ]                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3ë‹¨ê³„: ì‹¤í–‰ ì¤€ë¹„ âš™ï¸

```
Orchestratorê°€ ì‹¤í–‰ ì‹œì‘
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
orchestrator.start_pipeline(execution_plan)

         â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       ExecutionContext                  â”‚
â”‚  (ì´ íŠ¹ì • ì‹¤í–‰ì˜ ì»¨í…ìŠ¤íŠ¸)              â”‚
â”‚                                         â”‚
â”‚  run_id: "run_20251015_001"            â”‚
â”‚  dag_id: "etl_pipeline"                â”‚
â”‚  execution_plan: <ìœ„ì—ì„œ ë§Œë“  plan>     â”‚
â”‚  io_manager: <FilesystemIOManager>     â”‚
â”‚  metadata: {"user": "alice"}           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4ë‹¨ê³„: Task ì‹¤í–‰ ì¤€ë¹„ ğŸ¯

```
Orchestratorê°€ ê°œë³„ Task ì‹¤í–‰ ì¤€ë¹„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

í˜„ì¬ ìƒíƒœ:
  completed_tasks = {}  (ì•„ë¬´ê²ƒë„ ì™„ë£Œ ì•ˆ ë¨)
  ready_tasks = ["extract_sales"]  (ì˜ì¡´ì„± ì—†ìŒ)

         â†“

Orchestrator._create_executable_task("extract_sales")

         â†“ ExecutionContext ì‚¬ìš©
         â†“ TaskRegistryì—ì„œ TaskMetadata ì¡°íšŒ
         â†“ upstream í™•ì¸ (ì—†ìŒ)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ExecutableTask (1)                 â”‚
â”‚  (Workerê°€ ì‹¤í–‰í•  íŒ¨í‚¤ì§€)               â”‚
â”‚                                         â”‚
â”‚  run_id: "run_20251015_001"            â”‚
â”‚  task_name: "extract_sales"            â”‚
â”‚  task_result_id: "result_001"          â”‚
â”‚  task_metadata: <TaskMetadata>         â”‚
â”‚    â”œâ”€ func: <function extract_sales>   â”‚
â”‚    â”œâ”€ dependencies: []                 â”‚
â”‚    â””â”€ ...                              â”‚
â”‚  inputs: {}  (ì˜ì¡´ì„± ì—†ìŒ)              â”‚
â”‚  retry_count: 0                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5ë‹¨ê³„: Worker ì‹¤í–‰ âš¡

```
Workerê°€ ExecutableTask ë°›ì•„ì„œ ì‹¤í–‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Worker                        â”‚
â”‚                                         â”‚
â”‚  1. ExecutableTask ë°›ìŒ                 â”‚
â”‚     â†“                                   â”‚
â”‚  2. inputs í™•ì¸ (ë¹„ì–´ìˆìŒ)              â”‚
â”‚     â†“                                   â”‚
â”‚  3. task_metadata.func ì‹¤í–‰             â”‚
â”‚     result = extract_sales()            â”‚
â”‚     # pd.DataFrame({"sales": [100,200]})â”‚
â”‚     â†“                                   â”‚
â”‚  4. io_managerë¡œ ê²°ê³¼ ì €ì¥              â”‚
â”‚     io_manager.save(                    â”‚
â”‚       "extract_sales",                  â”‚
â”‚       "run_20251015_001",               â”‚
â”‚       "result_001",                     â”‚
â”‚       result                            â”‚
â”‚     )                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â†“ íŒŒì¼ì‹œìŠ¤í…œì— ì €ì¥

ğŸ“ .dp-poc/runs/
  â””â”€ run_20251015_001/
     â””â”€ extract_sales/
        â””â”€ result_001.pkl  âœ… ì €ì¥ë¨!
```

### 6ë‹¨ê³„: ë‹¤ìŒ Task ì‹¤í–‰ ğŸ”„

```
Orchestratorê°€ ë‹¤ìŒ Task ì¤€ë¹„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

í˜„ì¬ ìƒíƒœ:
  completed_tasks = {
    "extract_sales": "result_001"  âœ…
  }
  ready_tasks = ["transform"]  (ì˜ì¡´ì„± ì¶©ì¡±!)

         â†“

Orchestrator._create_executable_task("transform", completed_tasks)

         â†“ upstream í™•ì¸: ["extract_sales"]
         â†“ "extract_sales"ì˜ ê²°ê³¼ ì°¾ê¸°
         â†“ io_manager.exists(...) â†’ True

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      ExecutableTask (2)                 â”‚
â”‚                                         â”‚
â”‚  run_id: "run_20251015_001"            â”‚
â”‚  task_name: "transform"                â”‚
â”‚  task_result_id: "result_002"          â”‚
â”‚  task_metadata: <TaskMetadata>         â”‚
â”‚    â”œâ”€ func: <function transform>       â”‚
â”‚    â”œâ”€ dependencies: ["extract_sales"]  â”‚
â”‚    â””â”€ ...                              â”‚
â”‚  inputs: {                             â”‚  â† ì¤‘ìš”!
â”‚    "extract_sales": (                  â”‚
â”‚      "extract_sales",                  â”‚
â”‚      "result_001"                      â”‚
â”‚    )                                   â”‚
â”‚  }                                     â”‚
â”‚  retry_count: 0                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â†“ Workerë¡œ ì „ë‹¬

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Worker                        â”‚
â”‚                                         â”‚
â”‚  1. ExecutableTask ë°›ìŒ                 â”‚
â”‚     â†“                                   â”‚
â”‚  2. inputsì—ì„œ "extract_sales" ë°œê²¬     â”‚
â”‚     â†“                                   â”‚
â”‚  3. io_managerë¡œ ì´ì „ ê²°ê³¼ ë¡œë“œ         â”‚
â”‚     extract_sales_data = io_manager.load(â”‚
â”‚       "extract_sales",                  â”‚
â”‚       "run_20251015_001",               â”‚
â”‚       "result_001"                      â”‚
â”‚     )                                   â”‚
â”‚     # pd.DataFrame({"sales": [100,200]})â”‚
â”‚     â†“                                   â”‚
â”‚  4. task_metadata.func ì‹¤í–‰ (íŒŒë¼ë¯¸í„° ì£¼ì…)â”‚
â”‚     result = transform(                 â”‚
â”‚       extract_sales=extract_sales_data  â”‚
â”‚     )                                   â”‚
â”‚     # pd.DataFrame({"sales": [200,400]})â”‚
â”‚     â†“                                   â”‚
â”‚  5. io_managerë¡œ ê²°ê³¼ ì €ì¥              â”‚
â”‚     io_manager.save(                    â”‚
â”‚       "transform",                      â”‚
â”‚       "run_20251015_001",               â”‚
â”‚       "result_002",                     â”‚
â”‚       result                            â”‚
â”‚     )                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

         â†“

ğŸ“ .dp-poc/runs/
  â””â”€ run_20251015_001/
     â”œâ”€ extract_sales/
     â”‚  â””â”€ result_001.pkl  âœ…
     â””â”€ transform/
        â””â”€ result_002.pkl  âœ… ìƒˆë¡œ ì €ì¥ë¨!
```

## ğŸ¯ ì „ì²´ íë¦„ ìš”ì•½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Taskì˜ ì „ì²´ ì—¬ì •                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1ï¸âƒ£ ì •ì˜ ë‹¨ê³„ (ê°œë°œ ì‹œê°„)
   @task decorator
        â†“
   TaskMetadata ìƒì„±
        â†“
   TaskRegistryì— ë“±ë¡ âœ…

2ï¸âƒ£ ê³„íš ë‹¨ê³„ (ì‹¤í–‰ ì „)
   Planner.create_execution_plan()
        â†“
   DAGBuilderê°€ TaskRegistryì—ì„œ ì¡°íšŒ
        â†“
   DAG ìƒì„± (Nodeë“¤ì˜ ê·¸ë˜í”„)
        â†“
   DAGValidator ê²€ì¦
        â†“
   DAGAnalyzer ë¶„ì„ (ìˆœì„œ, ë ˆë²¨)
        â†“
   ExecutionPlan ìƒì„± âœ…

3ï¸âƒ£ ì‹¤í–‰ ì¤€ë¹„ ë‹¨ê³„ (ëŸ°íƒ€ì„)
   Orchestrator.start_pipeline(execution_plan)
        â†“
   ExecutionContext ìƒì„± (run_id í• ë‹¹)
        â†“
   TaskDependencyResolver ìƒì„± âœ…

4ï¸âƒ£ Task ìƒì„± ë‹¨ê³„ (ê° Taskë§ˆë‹¤)
   Orchestrator._create_executable_task()
        â†“
   upstream ê²°ê³¼ ì°¾ê¸° (io_manager)
        â†“
   ExecutableTask ìƒì„±
        â†“
   inputs ë§¤í•‘ ì¶”ê°€ âœ…

5ï¸âƒ£ ì‹¤í–‰ ë‹¨ê³„ (Worker)
   Worker.execute(executable_task)
        â†“
   inputsë¡œë¶€í„° ì´ì „ ê²°ê³¼ ë¡œë“œ
        â†“
   task_metadata.func ì‹¤í–‰
        â†“
   ê²°ê³¼ë¥¼ io_managerë¡œ ì €ì¥ âœ…

6ï¸âƒ£ ë°˜ë³µ (ëª¨ë“  Task ì™„ë£Œê¹Œì§€)
   completed_tasks ì—…ë°ì´íŠ¸
        â†“
   get_ready_tasks() í˜¸ì¶œ
        â†“
   4ï¸âƒ£ ë‹¨ê³„ë¡œ ëŒì•„ê°€ê¸°
        â†“
   ëª¨ë“  Task ì™„ë£Œ ì‹œ ì¢…ë£Œ âœ…
```

## ğŸ”‘ í•µì‹¬ ê°œë… ì •ë¦¬

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TaskMetadata                                      â”‚
â”‚  = Taskì˜ "ì •ì˜"                                   â”‚
â”‚  (í•¨ìˆ˜, ì˜ì¡´ì„±, ì„¤ì • ë“±)                           â”‚
â”‚  í•œ ë²ˆ ë§Œë“¤ì–´ì§€ë©´ ë³€í•˜ì§€ ì•ŠìŒ                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“ ì—¬ëŸ¬ ê°œ ëª¨ì—¬ì„œ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DAG / ExecutionPlan                               â”‚
â”‚  = Taskë“¤ì˜ "ì‹¤í–‰ ê³„íš"                            â”‚
â”‚  (ìˆœì„œ, ì˜ì¡´ì„± ê´€ê³„)                               â”‚
â”‚  ì¬ì‚¬ìš© ê°€ëŠ¥                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“ ì‹¤ì œ ì‹¤í–‰í•  ë•Œ
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ExecutionContext                                  â”‚
â”‚  = íŠ¹ì • ì‹¤í–‰ì˜ "ì»¨í…ìŠ¤íŠ¸"                          â”‚
â”‚  (run_id, ì–´ë–¤ plan, ì–´ë””ì— ì €ì¥)                  â”‚
â”‚  ì‹¤í–‰ë§ˆë‹¤ ìƒˆë¡œ ìƒì„±                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“ ê° Taskë§ˆë‹¤
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ExecutableTask                                    â”‚
â”‚  = Workerê°€ ì‹¤í–‰í•  "íŒ¨í‚¤ì§€"                        â”‚
â”‚  (ì–´ë–¤ Task, ì–´ë–¤ ì…ë ¥, ì–´ë””ì— ì €ì¥)                â”‚
â”‚  Task ì‹¤í–‰ë§ˆë‹¤ ìƒˆë¡œ ìƒì„±                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“ Workerê°€ ì‹¤í–‰
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TaskResult                                        â”‚
â”‚  = ì‹¤í–‰ ê²°ê³¼                                       â”‚
â”‚  io_managerë¡œ íŒŒì¼ì‹œìŠ¤í…œì— ì €ì¥                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---


## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

ì´ í”„ë¡œì íŠ¸ëŠ” 5ê°œì˜ í•µì‹¬ ì‹œìŠ¤í…œìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

1. **Event System** ğŸ”” - ë¹„ë™ê¸° ì´ë²¤íŠ¸ ë©”ì‹œì§• ì‹œìŠ¤í…œ
2. **Scheduler System** â° - ë‹¤ì–‘í•œ íŠ¸ë¦¬ê±° ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ
3. **Task Registry** ğŸ“‹ - Task ë“±ë¡ ë° ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ
4. **Planner** ğŸ—ºï¸ - DAG ê¸°ë°˜ ì‹¤í–‰ ê³„íš ì‹œìŠ¤í…œ
5. **I/O Manager** ğŸ’¾ - Task ê²°ê³¼ ì €ì¥ ë° ë¡œë”© ì‹œìŠ¤í…œ

### Event System
- í† í”½ ê¸°ë°˜ pub/sub íŒ¨í„´
- ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ ë§¤ì¹­ (`*`, `**`)
- ë¹„ë™ê¸° ì œë„ˆë ˆì´í„° ê¸°ë°˜ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼
- Hexagonal Architecture (í¬íŠ¸ & ì–´ëŒ‘í„°)
- **MultiprocessQueue**: `multiprocessing.Queue` ê¸°ë°˜ í”„ë¡œì„¸ìŠ¤ ê°„ í†µì‹  (IPC) ì§€ì›
  - Async/Sync í†µí•© ì§€ì›
  - í”„ë¡œì„¸ìŠ¤ ì•ˆì „í•œ Queue êµ¬í˜„

### Scheduler System
- **CronTrigger**: Crontab ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§
- **APITrigger**: API í˜¸ì¶œ ê¸°ë°˜ íŠ¸ë¦¬ê±°
- **EventTrigger**: ì´ë²¤íŠ¸ ìˆ˜ì‹  ê¸°ë°˜ íŠ¸ë¦¬ê±°
- FastAPI í†µí•© ì§€ì›

### Task Registry
- ë™ê¸°/ë¹„ë™ê¸° í•¨ìˆ˜ ì§€ì›
- ìë™ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ (íƒ€ì… íŒíŠ¸ ê¸°ë°˜)
- Task ê°„ ì˜ì¡´ì„± ê´€ë¦¬
- íƒœê·¸ ê¸°ë°˜ ë¶„ë¥˜ ë° ì¡°íšŒ
- **ê³ ê¸‰ Task ë©”íƒ€ë°ì´í„°**:
  - `max_retries`: Task ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ íšŸìˆ˜
  - `fail_safe`: ì‹¤íŒ¨ ì‹œì—ë„ íŒŒì´í”„ë¼ì¸ ê³„ì† ì‹¤í–‰ ì—¬ë¶€
  - `stream_output`: Generator ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ì§€ì›
  - `timeout`: Task ì‹¤í–‰ ì‹œê°„ ì œí•œ (ì´ˆ)

### Planner
- DAG(Directed Acyclic Graph) ìë™ ìƒì„±
- ìˆœí™˜ ì°¸ì¡° ê°ì§€ (Cycle Detection)
- ìœ„ìƒ ì •ë ¬ (Topological Sort)
- ë³‘ë ¬ ì‹¤í–‰ ë ˆë²¨ ê³„ì‚°
- ì˜ì¡´ì„± ê²€ì¦
- **Content-based DAG ID**: ë™ì¼í•œ êµ¬ì¡°ì˜ DAGëŠ” ë™ì¼í•œ ID ìƒì„± (í•´ì‹œ ê¸°ë°˜)
- **Schema Validator**: Task ê°„ íƒ€ì… í˜¸í™˜ì„± ê²€ì¦
  - Control Flow vs Data Flow Dependency êµ¬ë¶„
  - Named Arguments (íŒŒë¼ë¯¸í„° ì´ë¦„ = task ì´ë¦„)
  - Advanced Type Checking (Generic, Union, Inheritance)
  - Optional Parameters (ê¸°ë³¸ê°’ ìˆëŠ” íŒŒë¼ë¯¸í„°ëŠ” ê²€ì¦ ì œì™¸)

### I/O Manager
- Hexagonal Architecture (í¬íŠ¸ & ì–´ëŒ‘í„°)
- Task ê²°ê³¼ ì €ì¥/ë¡œë”© ì¶”ìƒí™”
- **FilesystemIOManager**: ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜ êµ¬í˜„
  - Pickle ê¸°ë°˜ ì§ë ¬í™”
  - Run ID ê¸°ë°˜ ê²©ë¦¬ (ê° ì‹¤í–‰ì€ ë…ë¦½ëœ ê³µê°„)
  - Task Result ID ì§€ì› (ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ì˜ ê°œë³„ ê²°ê³¼ ì €ì¥)
  - êµ¬ì¡°í™”ëœ ë””ë ‰í† ë¦¬: `{base_path}/{run_id}/{task_name}/{task_result_id}.pkl`
- Run ë‹¨ìœ„ ê´€ë¦¬ (list, clear ì§€ì›)

## ğŸ“¦ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
dp-poc/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ event_system/           # ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ domain/            # í¬íŠ¸ ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ broker_port.py
â”‚   â”‚   â”‚   â”œâ”€â”€ publisher_port.py
â”‚   â”‚   â”‚   â”œâ”€â”€ consumer_port.py
â”‚   â”‚   â”‚   â”œâ”€â”€ queue_port.py
â”‚   â”‚   â”‚   â””â”€â”€ events.py
â”‚   â”‚   â”œâ”€â”€ infrastructure/    # ì–´ëŒ‘í„° êµ¬í˜„
â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory_broker.py
â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory_publisher.py
â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory_consumer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory_queue.py
â”‚   â”‚   â”‚   â””â”€â”€ multiprocess_queue.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ topic_matcher.py
â”‚   â”‚
â”‚   â”œâ”€â”€ scheduler/              # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ domain/            # í¬íŠ¸ ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ trigger_port.py
â”‚   â”‚   â”‚   â””â”€â”€ scheduler_port.py
â”‚   â”‚   â”œâ”€â”€ infrastructure/    # íŠ¸ë¦¬ê±° êµ¬í˜„
â”‚   â”‚   â”‚   â”œâ”€â”€ cron_trigger.py
â”‚   â”‚   â”‚   â”œâ”€â”€ api_trigger.py
â”‚   â”‚   â”‚   â”œâ”€â”€ event_trigger.py
â”‚   â”‚   â”‚   â”œâ”€â”€ manual_trigger.py
â”‚   â”‚   â”‚   â”œâ”€â”€ scheduler.py
â”‚   â”‚   â”‚   â””â”€â”€ trigger_factory.py
â”‚   â”‚   â”œâ”€â”€ api/               # FastAPI í†µí•©
â”‚   â”‚   â”‚   â”œâ”€â”€ fastapi_integration.py
â”‚   â”‚   â”‚   â””â”€â”€ example_fastapi.py
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ task_registry/          # Task Registry ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ domain/            # ë„ë©”ì¸ ëª¨ë¸
â”‚   â”‚   â”‚   â”œâ”€â”€ task_model.py
â”‚   â”‚   â”‚   â””â”€â”€ registry_port.py
â”‚   â”‚   â”œâ”€â”€ infrastructure/    # Registry êµ¬í˜„
â”‚   â”‚   â”‚   â””â”€â”€ task_registry.py
â”‚   â”‚   â”œâ”€â”€ utils/             # ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â”‚   â””â”€â”€ schema_utils.py
â”‚   â”‚   â”œâ”€â”€ decorator.py       # @task ë°ì½”ë ˆì´í„°
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ planner/                # Planner ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ domain/            # ë„ë©”ì¸ ë¡œì§
â”‚   â”‚   â”‚   â”œâ”€â”€ node.py        # Node ëª¨ë¸
â”‚   â”‚   â”‚   â”œâ”€â”€ dag.py         # DAG í´ë˜ìŠ¤
â”‚   â”‚   â”‚   â”œâ”€â”€ dag_builder.py # DAG ìƒì„±
â”‚   â”‚   â”‚   â”œâ”€â”€ execution_plan.py  # ì‹¤í–‰ ê³„íš
â”‚   â”‚   â”‚   â”œâ”€â”€ schema_validator.py  # Schema ê²€ì¦
â”‚   â”‚   â”‚   â””â”€â”€ planner.py     # Planner í†µí•©
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ io_manager/             # I/O Manager ì‹œìŠ¤í…œ
â”‚   â”‚   â”œâ”€â”€ domain/            # í¬íŠ¸ ì¸í„°í˜ì´ìŠ¤
â”‚   â”‚   â”‚   â””â”€â”€ io_manager_port.py
â”‚   â”‚   â””â”€â”€ infrastructure/    # ì–´ëŒ‘í„° êµ¬í˜„
â”‚   â”‚       â””â”€â”€ filesystem_io_manager.py
â”‚   â”‚
â”‚   â””â”€â”€ main.py                # ë©”ì¸ ì§„ì…ì 
â”‚
â”œâ”€â”€ examples/                   # ì˜ˆì œ ì½”ë“œ
â”‚   â”œâ”€â”€ schema_extraction_demo.py
â”‚   â”œâ”€â”€ task_registry_example.py
â”‚   â”œâ”€â”€ planner_example.py
â”‚   â””â”€â”€ schema_validator_example.py
â”‚
â”œâ”€â”€ tests/                      # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ event_system/
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”œâ”€â”€ task_registry/
â”‚   â”œâ”€â”€ planner/
â”‚   â”œâ”€â”€ io_manager/
â”‚   â””â”€â”€ benchmark/
â”‚
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­
- Python 3.12+
- [uv](https://github.com/astral-sh/uv) (Python íŒ¨í‚¤ì§€ ê´€ë¦¬ì)

### ì„¤ì¹˜

```bash
# ê°œë°œ í™˜ê²½ ì„¤ì • (ê°€ìƒí™˜ê²½ ìƒì„± + ì˜ì¡´ì„± ì„¤ì¹˜)
make dev

# ë˜ëŠ” ì˜ì¡´ì„±ë§Œ ì„¤ì¹˜
make install
```

### ê¸°ë³¸ ì‹¤í–‰

```bash
# ë©”ì¸ ë°ëª¨ ì‹¤í–‰
make run

# íŒ¨í„´ ë§¤ì¹­ ë°ëª¨
python -m app.main --pattern

# Task Registry ì˜ˆì œ
python -m examples.task_registry_example

# Schema ì¶”ì¶œ ë°ëª¨
python -m examples.schema_extraction_demo

# Planner ì˜ˆì œ
python -m examples.planner_example
```

## ğŸ’¡ ì‚¬ìš© ì˜ˆì œ

### 1. Event System ì‚¬ìš©í•˜ê¸°

```python
from app.event_system.domain.events import EventBase
from app.event_system.infrastructure import InMemoryBroker, InMemoryPublisher, InMemoryConsumer
import asyncio

# Setup
broker = InMemoryBroker()
publisher = InMemoryPublisher(broker)
consumer = InMemoryConsumer(broker)

# Event ì •ì˜
class DataEvent(EventBase):
    def __init__(self, topic: str, data: dict, **kwargs):
        super().__init__(topic=topic, data=data, **kwargs)
        self.data = data

# Publish
await publisher.publish("data.ingestion", DataEvent(topic="data.ingestion", data={"rows": 100}))

# Consume
async for event in consumer.consume("data.ingestion"):
    print(f"Received: {event.data}")
```

### 2. Scheduler ì‚¬ìš©í•˜ê¸°

```python
from app.scheduler import Scheduler, create_cron_trigger, create_api_trigger

# Cron ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§
cron_trigger = create_cron_trigger(
    cron_expression="0 9 * * *",  # ë§¤ì¼ ì˜¤ì „ 9ì‹œ
    event_factory=lambda: DailyReportEvent(topic="reports.daily")
)

scheduler = Scheduler(publisher)
await scheduler.register_trigger("daily_report", cron_trigger, "reports.daily")
await scheduler.start()
```

### 3. Task Registry ì‚¬ìš©í•˜ê¸°

```python
from app.task_registry import task, get_registry

# Task ë“±ë¡
@task(name="extract_data", tags=["etl", "extract"])
def extract_data() -> dict[str, list[int]]:
    return {"data": [1, 2, 3, 4, 5]}

@task(name="transform_data", tags=["etl", "transform"], dependencies=["extract_data"])
async def transform_data(data: dict[str, list[int]]) -> list[int]:
    return [x * 2 for x in data["data"]]

# Registry ì¡°íšŒ
registry = get_registry()
task_info = registry.get("extract_data")
print(f"Task: {task_info.name}, Async: {task_info.is_async}")
```

### 4. Planner ì‚¬ìš©í•˜ê¸°

```python
from app.task_registry import task
from app.planner import get_planner

# Task ë“±ë¡ (ì˜ì¡´ì„± í¬í•¨)
@task(name="extract", tags=["etl"])
def extract():
    return {"data": [1, 2, 3]}

@task(name="transform", tags=["etl"], dependencies=["extract"])
def transform():
    return [2, 4, 6]

@task(name="load", tags=["etl"], dependencies=["transform"])
def load():
    pass

# ì‹¤í–‰ ê³„íš ìƒì„±
planner = get_planner()
plan = planner.create_execution_plan(tags=["etl"])

print(f"Execution order: {plan.execution_order}")
# Output: ['extract', 'transform', 'load']

print(f"Parallel levels: {plan.parallel_levels}")
# Output: [['extract'], ['transform'], ['load']]

# ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜
completed = set()
for level_tasks in plan.parallel_levels:
    # ì´ ë ˆë²¨ì˜ Taskë“¤ì€ ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥
    for task_id in level_tasks:
        print(f"Executing {task_id}...")
    completed.update(level_tasks)
```

### 5. I/O Manager ì‚¬ìš©í•˜ê¸°

```python
from app.io_manager import FilesystemIOManager
from pathlib import Path

# I/O Manager ì´ˆê¸°í™”
io_manager = FilesystemIOManager(base_path=Path("/tmp/dp-poc-runs"))

# Run ID ìƒì„± (ë³´í†µ UUID ì‚¬ìš©)
run_id = "run_20250115_001"

# Task ê²°ê³¼ ì €ì¥
data = {"processed": [1, 2, 3, 4, 5], "count": 5}
path = io_manager.save(
    run_id=run_id,
    task_name="extract_data",
    task_result_id="result_001",
    value=data
)
print(f"Saved to: {path}")

# Task ê²°ê³¼ ë¡œë”©
loaded_data = io_manager.load(
    run_id=run_id,
    task_name="extract_data",
    task_result_id="result_001"
)
print(f"Loaded: {loaded_data}")

# ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ ì§€ì›
for i, chunk in enumerate(data_generator()):
    io_manager.save(
        run_id=run_id,
        task_name="streaming_task",
        task_result_id=f"chunk_{i}",
        value=chunk
    )

# Run ë‚´ ëª¨ë“  ê²°ê³¼ ì¡°íšŒ
results = io_manager.list_results(run_id=run_id, task_name="streaming_task")
print(f"Found {len(results)} results")

# Run ì •ë¦¬
deleted_count = io_manager.clear_run(run_id=run_id)
print(f"Deleted {deleted_count} results")
```

### 6. ê³ ê¸‰ Task ë©”íƒ€ë°ì´í„° ì‚¬ìš©í•˜ê¸°

```python
from app.task_registry import task

@task(
    name="resilient_task",
    max_retries=3,              # ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 3ë²ˆ ì¬ì‹œë„
    fail_safe=True,             # ì‹¤íŒ¨í•´ë„ íŒŒì´í”„ë¼ì¸ ê³„ì† ì§„í–‰
    timeout=60,                 # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
    stream_output=False         # ë‹¨ì¼ ê²°ê³¼ ë°˜í™˜
)
def resilient_task(data: dict) -> dict:
    # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë“± ì‹¤íŒ¨ ê°€ëŠ¥í•œ ì‘ì—…
    return process_data(data)

@task(
    name="streaming_task",
    stream_output=True,         # Generator ë°˜í™˜
    timeout=300                 # 5ë¶„ íƒ€ì„ì•„ì›ƒ
)
def streaming_task(batch_size: int) -> Generator[list, None, None]:
    # ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
    for chunk in read_large_dataset(batch_size):
        yield process_chunk(chunk)
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
make test

# ì»¤ë²„ë¦¬ì§€ì™€ í•¨ê»˜ í…ŒìŠ¤íŠ¸
make test-cov

# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
pytest tests/event_system/ -v
pytest tests/scheduler/ -v
pytest tests/task_registry/ -v
pytest tests/planner/ -v
pytest tests/io_manager/ -v

# ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸
make test-benchmark
```

## ğŸ› ï¸ ê°œë°œ ë„êµ¬

### ì½”ë“œ í’ˆì§ˆ ë„êµ¬

- **ruff**: Python linter ë° formatter
- **mypy**: ì •ì  íƒ€ì… ì²´ì»¤
- **isort**: import ì •ë ¬
- **pre-commit**: Git pre-commit í›…

### Make ëª…ë ¹ì–´

```bash
# ì½”ë“œ í’ˆì§ˆ
make lint          # ì½”ë“œ ë¦°íŒ… (ìë™ ìˆ˜ì •)
make format        # ì½”ë“œ í¬ë§·íŒ…
make type-check    # íƒ€ì… ì²´í¬
make pre-commit    # pre-commit ì‹¤í–‰ (ëª¨ë“  íŒŒì¼)

# Pre-commit ì„¤ì •
make pre-commit-install  # pre-commit í›… ì„¤ì¹˜

# í…ŒìŠ¤íŠ¸
make test          # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
make test-cov      # ì»¤ë²„ë¦¬ì§€ì™€ í•¨ê»˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
make test-unit     # ìœ ë‹› í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
make test-integration  # í†µí•© í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
make test-benchmark    # ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰

# ì‹¤í–‰
make run           # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
```

## ğŸ“š ìƒì„¸ ë¬¸ì„œ

ê° ì‹œìŠ¤í…œì˜ ìƒì„¸í•œ ì‚¬ìš©ë²•ì€ ì•„ë˜ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì„¸ìš”:

- [Event System](app/event_system/) - ì´ë²¤íŠ¸ ë©”ì‹œì§• ì‹œìŠ¤í…œ
- [Scheduler System](app/scheduler/README.md) - ìŠ¤ì¼€ì¤„ë§ ì‹œìŠ¤í…œ
- [Task Registry](app/task_registry/README.md) - Task ê´€ë¦¬ ì‹œìŠ¤í…œ
- [Planner](app/planner/README.md) - DAG ê¸°ë°˜ ì‹¤í–‰ ê³„íš ì‹œìŠ¤í…œ
- [I/O Manager](app/io_manager/) - Task ê²°ê³¼ ì €ì¥/ë¡œë”© ì‹œìŠ¤í…œ

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### Hexagonal Architecture (í¬íŠ¸ & ì–´ëŒ‘í„°)

í”„ë¡œì íŠ¸ëŠ” Hexagonal Architectureë¥¼ ë”°ë¦…ë‹ˆë‹¤:

- **Domain Layer** (`domain/`): ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ê³¼ í¬íŠ¸(ì¸í„°í˜ì´ìŠ¤) ì •ì˜
- **Infrastructure Layer** (`infrastructure/`): ì–´ëŒ‘í„°(êµ¬í˜„ì²´)
- **API Layer** (`api/`): ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤ (FastAPI ë“±)

ì´ êµ¬ì¡°ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì¸í”„ë¼ êµ¬í˜„ìœ¼ë¡œë¶€í„° ì™„ì „íˆ ë¶„ë¦¬í•˜ì—¬:
- í…ŒìŠ¤íŠ¸ ìš©ì´ì„± í–¥ìƒ
- êµ¬í˜„ì²´ êµì²´ ìš©ì´ (In-Memory â†’ Redis, Kafka ë“±)
- ì˜ì¡´ì„± ì—­ì „ ì›ì¹™ ì¤€ìˆ˜

## ğŸ”„ í†µí•© ì˜ˆì œ

### ì „ì²´ ë°ì´í„° íŒŒì´í”„ë¼ì¸

```python
from app.event_system.infrastructure import InMemoryBroker, InMemoryPublisher, InMemoryConsumer
from app.scheduler import Scheduler, create_cron_trigger, create_event_trigger
from app.task_registry import task

# Event System ì„¤ì •
broker = InMemoryBroker()
publisher = InMemoryPublisher(broker)
consumer = InMemoryConsumer(broker)

# Task ì •ì˜
@task(name="extract", tags=["etl"])
async def extract_data():
    data = {"rows": [1, 2, 3, 4, 5]}
    await publisher.publish("data.extracted", DataExtractedEvent(topic="data.extracted", data=data))
    return data

@task(name="transform", tags=["etl"], dependencies=["extract"])
async def transform_data(data: dict):
    transformed = [x * 2 for x in data["rows"]]
    await publisher.publish("data.transformed", DataTransformedEvent(topic="data.transformed", data=transformed))
    return transformed

# Scheduler ì„¤ì •
scheduler = Scheduler(publisher)

# 1. ë§¤ì¼ ì˜¤ì „ 3ì‹œì— ë°ì´í„° ì¶”ì¶œ ì‹œì‘
extract_trigger = create_cron_trigger(
    cron_expression="0 3 * * *",
    event_factory=lambda: StartExtractEvent(topic="pipeline.start")
)

# 2. ì¶”ì¶œ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë³€í™˜ ì‹œì‘
transform_trigger = create_event_trigger(
    consumer=consumer,
    source_topic="data.extracted",
    event_factory=lambda event: StartTransformEvent(topic="pipeline.transform", data=event.data)
)

# ë“±ë¡ ë° ì‹œì‘
await scheduler.register_trigger("daily_extract", extract_trigger, "pipeline.start")
await scheduler.register_trigger("auto_transform", transform_trigger, "pipeline.transform")
await scheduler.start()
```

## ğŸ“ˆ ì„±ëŠ¥

ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ê²°ê³¼ (Apple M1, Python 3.12):

- **Event Throughput**: ~100K events/sec
- **Pattern Matching**: ~50K matches/sec
- **Task Registry**: ~1M lookups/sec

ìì„¸í•œ ë²¤ì¹˜ë§ˆí¬ëŠ” `tests/benchmark/` ì°¸ê³ 

## ğŸ”® í–¥í›„ ê³„íš

- [ ] Redis/Kafka ì–´ëŒ‘í„° êµ¬í˜„
- [x] ~~Task DAG ì‹¤í–‰ ê³„íš~~ (Planner ì™„ë£Œ)
- [x] ~~I/O Manager ì‹œìŠ¤í…œ~~ (FilesystemIOManager ì™„ë£Œ)
- [x] ~~MultiprocessQueue êµ¬í˜„~~ (ì™„ë£Œ)
- [ ] Task DAG ì‹¤í–‰ ì—”ì§„ (Executor)
  - [ ] ExecutableTask ë„ë©”ì¸ ëª¨ë¸
  - [ ] Worker í”„ë¡œì„¸ìŠ¤ êµ¬í˜„
  - [ ] Orchestrator êµ¬í˜„
  - [ ] MultiprocessExecutor í†µí•©
- [ ] MongoDB I/O Manager ì–´ëŒ‘í„°
- [ ] ë¶„ì‚° ìŠ¤ì¼€ì¤„ë§ ì§€ì›
- [ ] ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­
- [ ] UI ëŒ€ì‹œë³´ë“œ

## ğŸ“ ë¼ì´ì„¼ìŠ¤

Nothing...

## ğŸ¤ ê¸°ì—¬

ë‚´ë¶€ íŒ€ì›ë“¤ì˜ ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤. PRì„ ì˜¬ë¦¬ê¸° ì „ì—:

1. `make lint` ì‹¤í–‰
2. `make test` í†µê³¼ í™•ì¸
3. ìƒˆ ê¸°ëŠ¥ì€ í…ŒìŠ¤íŠ¸ ì½”ë“œ í¬í•¨
4. ë¬¸ì„œ ì—…ë°ì´íŠ¸
